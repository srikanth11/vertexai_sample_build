steps:
  # Step1: upload the file to gcs output bucket from files folder
  # - name: gcr.io/google.com/cloudsdktool/cloud-sdk
  #   args:
  #     - gsutil
  #     - cp
  #     - files/emp_cleaned_data_2k_lines.csv
  #     - gs://output_buk

  - name: gcr.io/tensile-nebula-406509/pypi-tools:3.7
    id: run-python-prg
    entrypoint: python
    args:
      - cmd
      - python sample.py

  # - name: gcr.io/google.com/cloudsdktool/cloud-sdk
  #   id: attach-date
  #   args:
  #     - bash
  #     - -c
  #     - |
  #       # Get today's date
  #       export TZ=Asia/Kolkata
  #       current_date=$(date +%d-%m-%y)
  #       time=$(date '+%I-%M%p')
  #       filename="emp_cleaned_data_${current_date}_${time}.csv"
  #       gsutil cp files/emp_cleaned_data_2k_lines.csv gs://output_buk/${filename}
    
  # Step2: create the training model in the gcs training registry
  # - name: gcr.io/google.com/cloudsdktool/cloud-sdk
  #   args:
  #     - gcloud
  #     - functions
  #     - call
  #     - function-1
  #     - --region
  #     - us-central1
  #     - --data
  #     - '{}'
options:
  logging: CLOUD_LOGGING_ONLY

